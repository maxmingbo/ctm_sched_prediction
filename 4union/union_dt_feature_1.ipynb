{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_list= [ '180609', '180610',\\\n",
    "#           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "#           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "#           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "#           '180711', '180712', '180713', '180714', '180715',\\\n",
    "d_list= [ '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725', \\\n",
    "          '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804', \\\n",
    "          '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "          '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822', \\\n",
    "\n",
    "          '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "          '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "          '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "          '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "          '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "          '181016', '181017', '181018', '181019', '181020', '181021']\n",
    "\n",
    "# d_list= [ '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "#           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "#           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708']\n",
    "\n",
    "# d_list= ['180709', '180710', \\\n",
    "#            '180711', '180712', '180713', '180714', '180715']\n",
    "\n",
    "day_all = ['180501', '180502', '180503', '180504', '180505', '180506', '180507', '180508', '180509', '180510',\\\n",
    "           '180511', '180512', '180513', '180514', '180515', '180516', '180517', '180518', '180519', '180520',\\\n",
    "           '180521', '180522', '180523', '180524', '180525', '180526', '180527', '180528', '180529', '180530',\\\n",
    "           '180531','180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "           '180711', '180712', '180713', '180714', '180715',\\\n",
    "           '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725',\\\n",
    "           '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804',\\\n",
    "           '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "           '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822',  \\\n",
    "           '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "           '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "           '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "            '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "           '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "           '181016', '181017', '181018', '181019', '181020', '181021','181022',\\\n",
    "           '181023', '181024', '181025', '181026', '181027', '181028', '181029','181101',\\\n",
    "            '181030','181031','181101' ,\\\n",
    "            '181102','181103','181104','181105', '181106', '181107', '181108', '181109','181110','181111','181111']\n",
    "\n",
    "common_job_head = ('SYS','FW','LD','EX','EXM','EXZ','STG','PDM','NDS','RT','TS','BRTL',\\\n",
    "          'HEES','RF','TR', 'TRZ','TRM','TDD','ARTP','SUB','RSM','ARTC','HS','FR','TRM','BFMC')\n",
    "common_nodegroup = ('GRP_TD_AGENT','GRP_FS_AGENT','GRP_DS_AGENT','GRP_DB_AGENT','10.6.123.51','GRP_OFB_AGENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['day_0_bef_start_time','day_0_bef_end_time','day_7_bef_start_time','day_7_bef_end_time','day_8_bef_start_time',\\\n",
    "    'day_8_bef_end_time','day_9_bef_start_time','day_9_bef_end_time','day_10_bef_start_time','day_10_bef_end_time',\\\n",
    "    'day_11_bef_start_time','day_11_bef_end_time','day_12_bef_start_time','day_12_bef_end_time','day_13_bef_start_time',\\\n",
    "    'day_13_bef_end_time','day_14_bef_start_time','day_14_bef_end_time','day_1_7_bef_start_time_max','day_1_14_bef_start_time_max',\\\n",
    "    'day_1_7_bef_end_time_max','day_1_14_bef_end_time_max','day_1_7_bef_start_time_min','day_1_14_bef_start_time_min',\\\n",
    "    'day_1_7_bef_end_time_min','day_1_14_bef_end_time_min','day_1_7_bef_start_time_median','day_1_14_bef_start_time_median',\\\n",
    "    'day_1_7_bef_end_time_median','day_1_14_bef_end_time_median','day_1_7_bef_start_time_mean','day_1_14_bef_start_time_mean',\\\n",
    "    'day_1_7_bef_end_time_mean','day_1_14_bef_end_time_mean','day_1_7_bef_start_time_std','day_1_14_bef_start_time_std',\\\n",
    "    'day_1_7_bef_end_time_std','day_1_14_bef_end_time_std','day_7_bef_no_end_time','day_14_bef_no_end_time','avg_start_error']\n",
    "def replace_head(job_head):\n",
    "    if job_head in common_job_head:\n",
    "        return job_head\n",
    "    else:\n",
    "        return 'otherhead'\n",
    "def replace_nodegroup(node):\n",
    "    if node in common_nodegroup:\n",
    "        return node\n",
    "    else:\n",
    "        return 'othernode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#作业表统计特征 0-4点结束，按前缀分组\n",
    "job_fnish_at_0_4_count = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob3\\fnish_at_0_4_count.csv')\n",
    "job_fnish_at_0_4_count.index = job_fnish_at_0_4_count['day']\n",
    "del job_fnish_at_0_4_count['day']\n",
    "\n",
    "#事件表状态变化，按前缀--状态分组\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最新版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 181016 181017 181018 181019 181020 181021 181022 181023 181024 181025 181026 181027 181028 181029 181101 181030 181031 181101 181102 181103 181104 181105 181106 181107 181108 181109 181110 181111 "
     ]
    }
   ],
   "source": [
    "# d_list= ['180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "#           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "#           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "#           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "#           '180711', '180712', '180713', '180714', '180715',\\\n",
    "#          '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725', \\\n",
    "#           '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804', \\\n",
    "#           '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "#           '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822', \\\n",
    "\n",
    "#           '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "#           '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "#           '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "train_list = ['180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "          '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "          '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "          '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "          '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "           '181016', '181017', '181018', '181019', '181020', '181021',\\\n",
    "           '181022',\\\n",
    "            '181023', '181024', '181025', '181026', '181027', '181028', '181029','181101',\\\n",
    "            '181030','181031','181101' ,\\\n",
    "            '181102','181103','181104','181105', '181106', '181107', '181108', '181109','181110','181111']\n",
    "\n",
    "#加入事件特征\n",
    "evet_allday_count = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count.csv')\n",
    "evet_allday_count2 = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count_2.csv')\n",
    "evet_allday_count3 = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count_3.csv')\n",
    "\n",
    "evet_allday_count =  pd.concat([evet_allday_count,evet_allday_count2,evet_allday_count3], ignore_index=True)\n",
    "\n",
    "del evet_allday_count2\n",
    "del evet_allday_count3\n",
    "evet_allday_count.index = evet_allday_count['index']\n",
    "\n",
    "del evet_allday_count['index']\n",
    "    \n",
    "\n",
    "for day in train_list:\n",
    "    #day = '180623'\n",
    "    day_int = int(day)\n",
    "\n",
    "\n",
    "    ajob1 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob\\ajob_%s_1.csv'%day,low_memory=False)\n",
    "    cols = [cl for cl in ajob1.columns if cl not in del_cols]\n",
    "    ajob1 = ajob1\n",
    "    ajob2 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob2\\ajob_%s_2.csv'%day,low_memory=False)\n",
    "\n",
    "    train_gen = ajob1.merge(ajob2,on=['job_name','order_id','server'],how='inner')\n",
    "    \n",
    "    for cl in evet_allday_count.columns:\n",
    "        \n",
    "        train_gen[cl] = evet_allday_count[cl][day_int]\n",
    "\n",
    "    #加入哑变量 特征\n",
    "    train_gen['job_name_head']= train_gen['job_name_head'].apply(replace_head)\n",
    "    train_gen['nodegroup']= train_gen['nodegroup'].apply(replace_nodegroup)\n",
    "\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['task_type']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['priority']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['cmdline']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['job_name_head']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['nodegroup']),left_index=True,right_index=True)\n",
    "\n",
    "    for clm in ['job_name_head','nodegroup','cmdline','task_type','order_table','priority']:\n",
    "        #train_gen.drop(clm,axis=1)\n",
    "        train_gen.drop(clm,axis=1,inplace=True)\n",
    "\n",
    "    #将order_id加上server特征构建唯一索引\n",
    "    train_gen['server'] = train_gen['server'].apply(str)\n",
    "    train_gen['order_id'] = train_gen[['order_id','server']].apply(lambda x:x[0]+x[1],axis=1)\n",
    "\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['server']),left_index=True,right_index=True)\n",
    "    del train_gen['server']\n",
    "\n",
    "    day_i  = day_all.index(day)\n",
    "\n",
    "    #加入作业资源特征\n",
    "    job_res = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\resorce\\p_prod_%s.csv'%day)\n",
    "\n",
    "    train_gen = train_gen.merge(job_res,on='order_id',how='left')\n",
    "    \n",
    "        \n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    #加入事件表统计特征1\n",
    "    for cl in evet_allday_count.columns:\n",
    "        #train_gen[cl] = evet_allday_count.iloc[day,cl]\n",
    "        train_gen[cl] = evet_allday_count[cl][day_int]\n",
    "    #---------------------------------------------------------------------------------------------------\n",
    "    #加入job表0-4点统计特征\n",
    "    for cl in job_fnish_at_0_4_count.columns:\n",
    "        train_gen[cl] = job_fnish_at_0_4_count[cl][day_int]\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    #加入事件表，每个作业历史前7天状态统计\n",
    "    day_i_inall = day_all.index(day)\n",
    "    day_his_7 = day_all[day_i_inall-7]\n",
    "    evet_his_count = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\evet_count\\evet_count_%s.csv'%day_his_7)\n",
    "    sel_colms = [cl for cl in evet_his_count.columns if cl !='order_id']\n",
    "    #left outerjoin\n",
    "    train_gen = train_gen.merge(evet_his_count[sel_colms],on='job_name',how='left')\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "    #填充空值  无资源的作业\n",
    "    train_gen['p_prod'].fillna(-1,inplace=True)\n",
    "    train_gen['res_isnull'] = train_gen['p_prod'].apply(lambda x:x==-1).apply(int)\n",
    "\n",
    "    def get_job_n_daybefore_dt(n,jobname):\n",
    "\n",
    "        day = day_all[day_i - n]\n",
    "        #print(day)\n",
    "        day_begain = int('20'+day+'000000')\n",
    "        day_4 = int('20'+day+'040000') #实例化要在4点前，排除手工追数情况;\n",
    "        day_int = int(day)\n",
    "\n",
    "        evet = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\evet\\evet_dt_%s.csv'%day,low_memory=False)\n",
    "        evet = evet[evet.end_time.notnull()]\n",
    "\n",
    "        evet_dict = evet.groupby('job_name').dt.max().T.to_dict()\n",
    "\n",
    "        not_findjob = list(set(jobname)-set(evet_dict.keys()))\n",
    "\n",
    "        for job in not_findjob:\n",
    "            evet_dict[job] = None\n",
    "\n",
    "        return jobname.apply(lambda x:evet_dict[x])\n",
    "\n",
    "    #当天  dt \n",
    "    train_gen['day_bef_0_dt'] = get_job_n_daybefore_dt(0,train_gen['job_name'])\n",
    "    \n",
    "    for i in range(7,14):\n",
    "        train_gen['day_bef_%d_dt'%(i-6)] = get_job_n_daybefore_dt(i,train_gen['job_name'])\n",
    "\n",
    "    train_gen = train_gen.round(3)\n",
    "    train_gen.sample(frac=1).to_csv(r'E:\\jupyter\\CTM\\data_train\\train_dt\\with_res_%s_dt.csv'%day,index=False)\n",
    "    print(day,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有历史时间变量 无资源特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180605 180606 180607 180608 180609 180610 180611 180612 180613 180614 180615 180616 180617 180618 180619 180620 180621 180622 180623 180624 180625 180626 180627 180628 180629 180630 180701 180702 180703 180704 180705 180706 180707 180708 180709 180710 180711 180712 180713 180714 180715 "
     ]
    }
   ],
   "source": [
    "for day in d_list:\n",
    "    #day = '180623'\n",
    "    day_int = int(day)\n",
    "\n",
    "\n",
    "    ajob1 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob\\ajob_%s_1.csv'%day,low_memory=False)\n",
    "    cols = [cl for cl in ajob1.columns if cl not in del_cols]\n",
    "    ajob1 = ajob1\n",
    "    ajob2 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob2\\ajob_%s_2.csv'%day,low_memory=False)\n",
    "\n",
    "    #加入事件特征\n",
    "    evet_allday_count = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count.csv')\n",
    "    evet_allday_count.index = evet_allday_count['index']\n",
    "\n",
    "    train_gen = ajob1.merge(ajob2,on=['job_name','order_id','server'],how='inner')\n",
    "\n",
    "    del evet_allday_count['index']\n",
    "    for cl in evet_allday_count.columns:\n",
    "        #train_gen[cl] = evet_allday_count.iloc[day,cl]\n",
    "        train_gen[cl] = evet_allday_count[cl][day_int]\n",
    "\n",
    "    #加入哑变量 特征\n",
    "    train_gen['job_name_head']= train_gen['job_name_head'].apply(replace_head)\n",
    "    train_gen['nodegroup']= train_gen['nodegroup'].apply(replace_nodegroup)\n",
    "\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['task_type']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['priority']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['cmdline']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['job_name_head']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['nodegroup']),left_index=True,right_index=True)\n",
    "\n",
    "    for clm in ['job_name_head','nodegroup','cmdline','task_type','order_table','priority']:\n",
    "        #train_gen.drop(clm,axis=1)\n",
    "        train_gen.drop(clm,axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    train_gen['server'] = train_gen['server'].apply(str)\n",
    "\n",
    "    train_gen['order_id'] = train_gen[['order_id','server']].apply(lambda x:x[0]+x[1],axis=1)\n",
    "\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['server']),left_index=True,right_index=True)\n",
    "    del train_gen['server']\n",
    "    \n",
    "    day_i  = day_all.index(day)\n",
    "    def get_job_n_daybefore_dt(n,jobname):\n",
    "        \n",
    "        day = day_all[day_i - n]\n",
    "        #print(day)\n",
    "        day_begain = int('20'+day+'000000')\n",
    "        day_4 = int('20'+day+'040000') #实例化要在4点前，排除手工追数情况;\n",
    "        day_int = int(day)\n",
    "        \n",
    "        evet = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\evet\\evet_dt_%s.csv'%day,low_memory=False)\n",
    "        evet = evet[evet.end_time.notnull()]\n",
    "        \n",
    "        evet_dict = evet.groupby('job_name').dt.max().T.to_dict()\n",
    "        \n",
    "        not_findjob = list(set(jobname)-set(evet_dict.keys()))\n",
    "\n",
    "        for job in not_findjob:\n",
    "            evet_dict[job] = None\n",
    "        \n",
    "        return jobname.apply(lambda x:evet_dict[x])\n",
    "        \n",
    "    for i in range(0,4):\n",
    "        train_gen['day_bef_%d_dt'%i] = get_job_n_daybefore_dt(i,train_gen['job_name'])\n",
    "        \n",
    "    train_gen = train_gen.round(3)\n",
    "    train_gen.sample(frac=1).to_csv(r'E:\\jupyter\\CTM\\valid_data\\train_dt\\train_%s_dt.csv'%day,index=False)\n",
    "    print(day,end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加上资源特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 181016 181017 181018 181019 181020 181021 "
     ]
    }
   ],
   "source": [
    "# d_list= ['180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "#           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "#           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "#           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "#           '180711', '180712', '180713', '180714', '180715',\\\n",
    "#          '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725', \\\n",
    "#           '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804', \\\n",
    "#           '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "#           '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822', \\\n",
    "\n",
    "#           '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "#           '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "#           '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "d_list= [ '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "          '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "          '181016', '181017', '181018', '181019', '181020', '181021']\n",
    "\n",
    "#加入事件特征\n",
    "evet_allday_count = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count.csv')\n",
    "evet_allday_count2 = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count_2.csv')\n",
    "\n",
    "evet_allday_count =  pd.concat([evet_allday_count,evet_allday_count2], ignore_index=True)\n",
    "del evet_allday_count2\n",
    "evet_allday_count.index = evet_allday_count['index']\n",
    "\n",
    "del evet_allday_count['index']\n",
    "    \n",
    "\n",
    "for day in d_list:\n",
    "    #day = '180623'\n",
    "    day_int = int(day)\n",
    "\n",
    "\n",
    "    ajob1 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob\\ajob_%s_1.csv'%day,low_memory=False)\n",
    "    cols = [cl for cl in ajob1.columns if cl not in del_cols]\n",
    "    ajob1 = ajob1\n",
    "    ajob2 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob2\\ajob_%s_2.csv'%day,low_memory=False)\n",
    "\n",
    "    train_gen = ajob1.merge(ajob2,on=['job_name','order_id','server'],how='inner')\n",
    "    \n",
    "    for cl in evet_allday_count.columns:\n",
    "        #train_gen[cl] = evet_allday_count.iloc[day,cl]\n",
    "        train_gen[cl] = evet_allday_count[cl][day_int]\n",
    "\n",
    "    #加入哑变量 特征\n",
    "    train_gen['job_name_head']= train_gen['job_name_head'].apply(replace_head)\n",
    "    train_gen['nodegroup']= train_gen['nodegroup'].apply(replace_nodegroup)\n",
    "\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['task_type']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['priority']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['cmdline']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['job_name_head']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['nodegroup']),left_index=True,right_index=True)\n",
    "\n",
    "    for clm in ['job_name_head','nodegroup','cmdline','task_type','order_table','priority']:\n",
    "        #train_gen.drop(clm,axis=1)\n",
    "        train_gen.drop(clm,axis=1,inplace=True)\n",
    "\n",
    "    #将order_id加上server特征构建唯一索引\n",
    "    train_gen['server'] = train_gen['server'].apply(str)\n",
    "    train_gen['order_id'] = train_gen[['order_id','server']].apply(lambda x:x[0]+x[1],axis=1)\n",
    "\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['server']),left_index=True,right_index=True)\n",
    "    del train_gen['server']\n",
    "\n",
    "    day_i  = day_all.index(day)\n",
    "\n",
    "    #加入作业资源特征\n",
    "    job_res = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\resorce\\p_prod_%s.csv'%day)\n",
    "\n",
    "    train_gen = train_gen.merge(job_res,on='order_id',how='left')\n",
    "\n",
    "    #填充空值  无资源的作业\n",
    "    train_gen['p_prod'].fillna(-1,inplace=True)\n",
    "    train_gen['res_isnull'] = train_gen['p_prod'].apply(lambda x:x==-1).apply(int)\n",
    "\n",
    "    def get_job_n_daybefore_dt(n,jobname):\n",
    "\n",
    "        day = day_all[day_i - n]\n",
    "        #print(day)\n",
    "        day_begain = int('20'+day+'000000')\n",
    "        day_4 = int('20'+day+'040000') #实例化要在4点前，排除手工追数情况;\n",
    "        day_int = int(day)\n",
    "\n",
    "        evet = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\evet\\evet_dt_%s.csv'%day,low_memory=False)\n",
    "        evet = evet[evet.end_time.notnull()]\n",
    "\n",
    "        evet_dict = evet.groupby('job_name').dt.max().T.to_dict()\n",
    "\n",
    "        not_findjob = list(set(jobname)-set(evet_dict.keys()))\n",
    "\n",
    "        for job in not_findjob:\n",
    "            evet_dict[job] = None\n",
    "\n",
    "        return jobname.apply(lambda x:evet_dict[x])\n",
    "\n",
    "    #当天  dt \n",
    "    for i in range(0,8):\n",
    "        train_gen['day_bef_%d_dt'%i] = get_job_n_daybefore_dt(i,train_gen['job_name'])\n",
    "\n",
    "    train_gen = train_gen.round(3)\n",
    "    train_gen.sample(frac=1).to_csv(r'E:\\jupyter\\CTM\\valid_data\\train_dt\\with_res_%s_dt.csv'%day,index=False)\n",
    "    print(day,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
