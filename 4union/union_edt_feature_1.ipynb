{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0823- - 0827 td停止服务  将这些数据剔除\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_list= ['180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "#           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "#           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "#           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', \\\n",
    "         \n",
    "d_list = ['180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "          '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "          '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "          '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "          '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "          '181016', '181017', '181018', '181019', '181020', '181021',\\\n",
    "          '181022', '181023', '181024', '181025', '181026', '181027', '181028', '181029', '181030', \\\n",
    "           '181031', '181101', '181102', '181103', '181104', '181105', '181106', '181107', '181108', '181109',\\\n",
    "           '181110', '181111']\n",
    "\n",
    "day_all = ['180531','180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "           '180711', '180712', '180713', '180714', '180715',\\\n",
    "           '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725',\\\n",
    "           '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804',\\\n",
    "           '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "           '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822',  \\\n",
    "           '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "           '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "           '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "            '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "           '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "           '181016', '181017', '181018', '181019', '181020', '181021',\\\n",
    "            '181022', '181023', '181024', '181025', '181026', '181027', '181028', '181029', '181030', \\\n",
    "           '181031', '181101', '181102', '181103', '181104', '181105', '181106', '181107', '181108', '181109',\\\n",
    "           '181110', '181111']\n",
    "\n",
    "common_job_head = ('SYS','FW','LD','EX','EXM','EXZ','STG','PDM','NDS','RT','TS','BRTL',\\\n",
    "          'HEES','RF','TR', 'TRZ','TRM','TDD','ARTP','SUB','RSM','ARTC','HS','FR','TRM','BFMC')\n",
    "common_nodegroup = ('GRP_TD_AGENT','GRP_FS_AGENT','GRP_DS_AGENT','GRP_DB_AGENT','10.6.123.51','GRP_OFB_AGENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_head(job_head):\n",
    "    if job_head in common_job_head:\n",
    "        return job_head\n",
    "    else:\n",
    "        return 'otherhead'\n",
    "def replace_nodegroup(node):\n",
    "    if node in common_nodegroup:\n",
    "        return node\n",
    "    else:\n",
    "        return 'othernode'\n",
    "\n",
    "    \n",
    "#加入事件特征\n",
    "evet_allday_count = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count.csv')\n",
    "evet_allday_count2 = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count_2.csv')\n",
    "evet_allday_count3 = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count_3.csv')\n",
    "\n",
    "evet_allday_count =  pd.concat([evet_allday_count,evet_allday_count2,evet_allday_count3], ignore_index=True)\n",
    "del evet_allday_count2\n",
    "del evet_allday_count3\n",
    "evet_allday_count.index = evet_allday_count['index']\n",
    "\n",
    "del evet_allday_count['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#作业表统计特征 0-4点结束，按前缀分组\n",
    "job_fnish_at_0_4_count = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob3\\fnish_at_0_4_count.csv')\n",
    "job_fnish_at_0_4_count.index = job_fnish_at_0_4_count['day']\n",
    "del job_fnish_at_0_4_count['day']\n",
    "\n",
    "#事件表状态变化，按前缀--状态分组\n",
    "evet_fnish_at_4_count = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\evet_count_byfolder\\evet_count_byfolder.csv')\n",
    "evet_fnish_at_4_count.index = evet_fnish_at_4_count['day']\n",
    "del evet_fnish_at_4_count['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 36)\n",
      "(76, 254)\n"
     ]
    }
   ],
   "source": [
    "print(job_fnish_at_0_4_count.shape)\n",
    "print(evet_fnish_at_4_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 181016 181017 181018 181019 181020 181021 181022 181023 181024 181025 181026 181027 181028 181029 181030 181031 181101 181102 181103 181104 181105 181106 181107 181108 181109 181110 181111 "
     ]
    }
   ],
   "source": [
    "for day in d_list:\n",
    "# for day in ('')\n",
    "    #day = '180623'\n",
    "    day_int = int(day)\n",
    "\n",
    "\n",
    "    ajob1 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob\\ajob_%s_1.csv'%day,low_memory=False)\n",
    "    ajob2 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob2\\ajob_%s_2.csv'%day,low_memory=False)\n",
    "\n",
    "    train_gen = ajob1.merge(ajob2,on=['job_name','order_id','server'],how='inner')\n",
    "\n",
    "\n",
    "    #加入哑变量 特征\n",
    "    train_gen['job_name_head']= train_gen['job_name_head'].apply(replace_head)\n",
    "    train_gen['nodegroup']= train_gen['nodegroup'].apply(replace_nodegroup)\n",
    "    train_gen['server'] = train_gen['server'].apply(str)\n",
    "    train_gen['order_id'] = train_gen[['order_id','server']].apply(lambda x:x[0]+x[1],axis=1)\n",
    "    \n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['task_type']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['priority']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['cmdline']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['job_name_head']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['nodegroup']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['server']),left_index=True,right_index=True)\n",
    "    \n",
    "    for clm in ['job_name_head','nodegroup','cmdline','task_type','order_table','priority','server']:\n",
    "        #train_gen.drop(clm,axis=1)\n",
    "        train_gen.drop(clm,axis=1,inplace=True)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    #加入事件表统计特征1\n",
    "    for cl in evet_allday_count.columns:\n",
    "        #train_gen[cl] = evet_allday_count.iloc[day,cl]\n",
    "        train_gen[cl] = evet_allday_count[cl][day_int]\n",
    "    #---------------------------------------------------------------------------------------------------\n",
    "    #加入job表0-4点统计特征\n",
    "    for cl in job_fnish_at_0_4_count.columns:\n",
    "        train_gen[cl] = job_fnish_at_0_4_count[cl][day_int]\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    for cl in evet_fnish_at_4_count.columns:\n",
    "        train_gen[cl] = evet_fnish_at_4_count[cl][day_int]\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    #加入作业资源特征\n",
    "    job_res = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\resorce\\p_prod_%s.csv'%day)\n",
    "\n",
    "    train_gen = train_gen.merge(job_res,on='order_id',how='left')\n",
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #加入事件表，每个作业历史前7天状态统计\n",
    "    day_i_inall = day_all.index(day)\n",
    "    day_his_7 = day_all[day_i_inall-7]\n",
    "    evet_his_count = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\evet_count\\evet_count_%s.csv'%day_his_7)\n",
    "    sel_colms = [cl for cl in evet_his_count.columns if cl !='order_id']\n",
    "    #left outerjoin\n",
    "    train_gen = train_gen.merge(evet_his_count[sel_colms],on='job_name',how='left')\n",
    "    #----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    train_gen = train_gen.round(3)\n",
    "    train_gen.sample(frac=1).to_csv(r'E:\\jupyter\\CTM\\data_train\\train\\edt_%s.csv'%day,index=False)\n",
    "    print(day,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下是历史版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180709 180710 180711 180712 180713 180714 180715 180716 180717 180718 180719 180720 180721 180722 180723 180724 180725 180726 180727 180728 180729 180730 180731 180801 180802 180803 180804 180805 180806 180807 180808 180809 180810 180811 180812 180813 180814 180815 180816 180817 180818 180819 180820 180821 180822 180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 181016 181017 181018 181019 181020 181021 "
     ]
    }
   ],
   "source": [
    "for day in d_list:\n",
    "# for day in ('')\n",
    "    #day = '180623'\n",
    "    day_int = int(day)\n",
    "\n",
    "\n",
    "    ajob1 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob\\ajob_%s_1.csv'%day,low_memory=False)\n",
    "    ajob2 = pd.read_csv(r'E:\\jupyter\\CTM\\data_processed\\ajob2\\ajob_%s_2.csv'%day,low_memory=False)\n",
    "\n",
    "    #加入事件特征\n",
    "#     evet_allday_count = pd.read_csv(r'E:/jupyter/CTM/data_processed/evet/evet_1_4hour_count_2.csv')\n",
    "#     evet_allday_count.index = evet_allday_count['index']\n",
    "#     del evet_allday_count['index']\n",
    "    \n",
    "    train_gen = ajob1.merge(ajob2,on=['job_name','order_id','server'],how='inner')\n",
    "    \n",
    "    for cl in evet_allday_count.columns:\n",
    "        #train_gen[cl] = evet_allday_count.iloc[day,cl]\n",
    "        train_gen[cl] = evet_allday_count[cl][day_int]\n",
    "\n",
    "    #加入哑变量 特征\n",
    "    train_gen['job_name_head']= train_gen['job_name_head'].apply(replace_head)\n",
    "    train_gen['nodegroup']= train_gen['nodegroup'].apply(replace_nodegroup)\n",
    "\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['task_type']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['priority']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['cmdline']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['job_name_head']),left_index=True,right_index=True)\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['nodegroup']),left_index=True,right_index=True)\n",
    "\n",
    "    for clm in ['job_name_head','nodegroup','cmdline','task_type','order_table','priority']:\n",
    "        #train_gen.drop(clm,axis=1)\n",
    "        train_gen.drop(clm,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    train_gen['server'] = train_gen['server'].apply(str)\n",
    "\n",
    "    train_gen['order_id'] = train_gen[['order_id','server']].apply(lambda x:x[0]+x[1],axis=1)\n",
    "\n",
    "    train_gen = pd.merge(train_gen,pd.get_dummies(train_gen['server']),left_index=True,right_index=True)\n",
    "    del train_gen['server']\n",
    "    \n",
    "    train_gen = train_gen.round(3)\n",
    "    train_gen.sample(frac=1).to_csv(r'E:\\jupyter\\CTM\\valid_data\\train\\train_%s_edt.csv'%day,index=False)\n",
    "    print(day,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练时不需要的特征\n",
    "v_date\torder_d\tfrom_time_1000_start\n",
    "start_time\tend_time\n",
    "order_id\tjob_name\n",
    "day_0_bef_start_time\tday_0_bef_end_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
