{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "# d_list=    ['180521', '180522', '180523', '180524', '180525', '180526', '180527', '180528', '180529', '180530',\\\n",
    "#            '180531','180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "#            '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "#            '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "#            '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "#            '180711', '180712', '180713', '180714', '180715',\\\n",
    "#             '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725',\\\n",
    "#            '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804',\\\n",
    "#            '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "#            '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822',  '180826',\\\n",
    "#            '180827', '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "#            '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "#            '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "#             '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "#            '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "#            '181016', '181017', '181018', '181019', '181020', '181021']\n",
    "\n",
    "d_list=    ['180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "           '180711', '180712', '180713', '180714', '180715',\\\n",
    "           '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725',\\\n",
    "           '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804',\\\n",
    "           '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "           '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822', \\\n",
    "            '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "           '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "           '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "            '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "           '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "           '181016', '181017', '181018', '181019', '181020', '181021',\\\n",
    "            '181022', '181023', '181024', '181025', '181026', '181027', '181028', '181029', '181030', \\\n",
    "           '181031', '181101', '181102', '181103', '181104', '181105', '181106', '181107', '181108', '181109',\\\n",
    "           '181110', '181111']\n",
    "\n",
    "print(len(d_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_jobname_head(s):\n",
    "    return s.split('_')[0]\n",
    "def f_get_hour(x):\n",
    "    t = str(x)[8:10]\n",
    "    return t\n",
    "def f_replace_oa(s):\n",
    "    return s.replace('oa','0a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "\n",
    "def read_data_everyday(day):\n",
    "    #day_i=14\n",
    "    #day = d_bef_list[day_i]\n",
    "\n",
    "#     day_l = '20'+day\n",
    "#     day_int = int(day)\n",
    "#     thred_hour = '040000'   #10点之前实例化截取\n",
    "#     # day_begain = int(day_l+'000000')\n",
    "#     order_t_thred = int(day_l+thred_hour)\n",
    "\n",
    "    train_src = pd.read_csv(r'E:\\jupyter\\CTM\\data_src\\ajob_0\\ajob_%s_0.csv'%day,low_memory=False)\n",
    "    \n",
    "    train_src['v_date'] = train_src['v_date'].apply(str)\n",
    "    \n",
    "    train_src['nodegroup']= train_src['nodegroup'].fillna('none')\n",
    "    \n",
    "#     train_src = train_src[train_src['odate']==day_int]\n",
    "#     train_src = train_src[train_src.order_time<=order_t_thred]\n",
    "    \n",
    "    train_src['priority'] = train_src['priority'].apply(f_replace_oa)\n",
    "    \n",
    "# print('src_data.shape',train_src.shape)\n",
    "#     if day == '180531':\n",
    "#         #0531包含2份切片\n",
    "#         print('    ',len(train_src))\n",
    "#         train_src = train_src[train_src.v_date =='180531_10']\n",
    "#         print('    ',len(train_src))\n",
    "\n",
    "    \n",
    "    return train_src\n",
    "\n",
    "def get_order_all_dict(df):\n",
    "    cls = ['nodegroup','order_table','prefix','priority']\n",
    "    res = []\n",
    "    for cl in cls:\n",
    "        res.append(df.groupby([cl])[cl].count().T.to_dict())\n",
    "    return res\n",
    "def get_order_all(cl,df):\n",
    "    return df.groupby([cl])[cl].count().T.to_dict()\n",
    "\n",
    "def get_start_hour_st(cl,df):\n",
    "    return df.groupby(['start_hour',cl])[cl].count()\n",
    "\n",
    "def get_end_hour_st(cl,df):\n",
    "    return df.groupby(['end_hour',cl])[cl].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180602 180603 180604 180605 180606 180607 180608 180609 180610 180611 180612 180613 180614 180615 180616 180617 180618 180619 180620 180621 180622 180623 180624 180625 180626 180627 180628 180629 180630 180701 180702 180703 180704 180705 180706 180707 180708 180709 180710 180711 180712 180713 180714 180715 180716 180717 180718 180719 180720 180721 180722 180723 180724 180725 180726 180727 180728 180729 180730 180731 180801 180802 180803 180804 180805 180806 180807 180808 180809 180810 180811 180812 180813 180814 180815 180816 180817 180818 180819 180820 180821 180822 180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 181016 181017 181018 181019 181020 181021 181022 181023 181024 181025 181026 181027 181028 181029 181030 181031 181101 181102 181103 181104 181105 181106 181107 181108 181109 181110 181111 nodegroup 158\n",
      "order_table 158\n",
      "prefix 158\n",
      "priority 158\n"
     ]
    }
   ],
   "source": [
    "#循环每一天   统计按各种分组个给作业完成情况  完成百分比\n",
    "#cls = ['nodegroup','order_table','prefix','priority']\n",
    "\n",
    "df_list = {'nodegroup':[],'order_table':[],'prefix':[],'priority':[]}\n",
    "\n",
    "for day_i in range(0,len(d_list)):\n",
    "    #天循环\n",
    "    day = d_list[day_i]\n",
    "    \n",
    "    dat = read_data_everyday(day)\n",
    "    dat['prefix'] = dat['job_name'].apply(f_get_jobname_head)\n",
    "    dat['start_hour'] = dat['start_time'].apply(f_get_hour)\n",
    "    \n",
    "    #order_groupby_all = get_order_all_dict(dat)\n",
    "    \n",
    "    \n",
    "    #del dat\n",
    "    #cls = ['priority']\n",
    "    \n",
    "    for cl in df_list.keys():\n",
    "        \n",
    "        # 分组统计循环,\n",
    "        \n",
    "        order_all = get_order_all(cl,dat)\n",
    "        end_hour_groupby = get_start_hour_st(cl,dat)\n",
    "        \n",
    "        #print(order_all.keys())\n",
    "        cl_dict = {}\n",
    "        \n",
    "        for cl_key in order_all.keys():\n",
    "            #每个分组下 取值统计\n",
    "            dict_val =[]\n",
    "            #print(cl_key)\n",
    "            for i in range(4):\n",
    "#                 if day=='180710' and i>=9:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue\n",
    "#                 elif day=='180711' and i>=8:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue\n",
    "#                 elif day=='180712' and i>=7:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue                    \n",
    "#                 elif day=='180713' and i>=6:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue                    \n",
    "#                 elif day=='180714' and i>=5:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue\n",
    "#                 elif day=='180715' and i>=4:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue\n",
    "                    \n",
    "                hour_str = '0'+str(i)\n",
    "                if cl_key not in end_hour_groupby[hour_str].keys():\n",
    "                    dict_val.append(0)\n",
    "                else:\n",
    "                    dict_val.append(end_hour_groupby[hour_str][cl_key]/order_all[cl_key])\n",
    "            cl_dict[cl_key] = dict_val\n",
    "            \n",
    "        tmp_df = pd.DataFrame(cl_dict,index=[day+'_0'+str(i) for i in range(4)])\n",
    "        #字典转换成dataFrame\n",
    "        \n",
    "        df_list[cl].append(tmp_df)\n",
    "    \n",
    "    del dat\n",
    "    print(day,end=' ')\n",
    "    \n",
    "#         for order_all[cl].keys\n",
    "#         for i in range(10):\n",
    "#             hour_str = '0'+str(i)\n",
    "\n",
    "for cl in df_list.keys():\n",
    "    print(cl,len(df_list[cl]))\n",
    "    df = pd.concat(df_list[cl])\n",
    "    df = df.round(2)\n",
    "    df.to_json(r'E:\\jupyter\\CTM\\data_processed\\state\\starthour_of_%s.json'%cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180602 180603 180604 180605 180606 180607 180608 180609 180610 180611 180612 180613 180614 180615 180616 180617 180618 180619 180620 180621 180622 180623 180624 180625 180626 180627 180628 180629 180630 180701 180702 180703 180704 180705 180706 180707 180708 180709 180710 180711 180712 180713 180714 180715 180716 180717 180718 180719 180720 180721 180722 180723 180724 180725 180726 180727 180728 180729 180730 180731 180801 180802 180803 180804 180805 180806 180807 180808 180809 180810 180811 180812 180813 180814 180815 180816 180817 180818 180819 180820 180821 180822 180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 181016 181017 181018 181019 181020 181021 181022 181023 181024 181025 181026 181027 181028 181029 181030 181031 181101 181102 181103 181104 181105 181106 181107 181108 181109 181110 181111 nodegroup 158\n",
      "order_table 158\n",
      "prefix 158\n",
      "priority 158\n"
     ]
    }
   ],
   "source": [
    "#循环每一天   统计按各种分组个给作业完成情况  完成百分比\n",
    "#cls = ['nodegroup','order_table','prefix','priority']\n",
    "\n",
    "df_list = {'nodegroup':[],'order_table':[],'prefix':[],'priority':[]}\n",
    "\n",
    "for day_i in range(0,158):\n",
    "    #天循环\n",
    "    day = d_list[day_i]\n",
    "    \n",
    "    dat = read_data_everyday(day)\n",
    "    dat['prefix'] = dat['job_name'].apply(f_get_jobname_head)\n",
    "    dat['end_hour'] = dat['end_time'].apply(f_get_hour)\n",
    "    \n",
    "    #order_groupby_all = get_order_all_dict(dat)\n",
    "    \n",
    "    \n",
    "    #del dat\n",
    "    #cls = ['priority']\n",
    "    \n",
    "    for cl in df_list.keys():\n",
    "        \n",
    "        # 分组统计循环,\n",
    "        \n",
    "        order_all = get_order_all(cl,dat)\n",
    "        end_hour_groupby = get_end_hour_st(cl,dat)\n",
    "        \n",
    "        #print(order_all.keys())\n",
    "        cl_dict = {}\n",
    "        \n",
    "        for cl_key in order_all.keys():\n",
    "            #每个分组下 取值统计\n",
    "            dict_val =[]\n",
    "            #print(cl_key)\n",
    "            for i in range(4):\n",
    "                #一下日期时间点之后都未完成，为空。\n",
    "#                 if day=='180710' and i>=9:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue\n",
    "#                 elif day=='180711' and i>=8:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue\n",
    "#                 elif day=='180712' and i>=7:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue                    \n",
    "#                 elif day=='180713' and i>=6:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue                    \n",
    "#                 elif day=='180714' and i>=5:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue\n",
    "#                 elif day=='180715' and i>=4:\n",
    "#                     dict_val.append(0)\n",
    "#                     continue\n",
    "                    \n",
    "                hour_str = '0'+str(i)\n",
    "                if cl_key not in end_hour_groupby[hour_str].keys():\n",
    "                    dict_val.append(0)\n",
    "                else:\n",
    "                    dict_val.append(end_hour_groupby[hour_str][cl_key]/order_all[cl_key])\n",
    "            cl_dict[cl_key] = dict_val\n",
    "            \n",
    "        tmp_df = pd.DataFrame(cl_dict,index=[day+'_0'+str(i) for i in range(4)])\n",
    "        #字典转换成dataFrame\n",
    "        \n",
    "        df_list[cl].append(tmp_df)\n",
    "    \n",
    "    del dat\n",
    "    print(day,end=' ')\n",
    "    \n",
    "#         for order_all[cl].keys\n",
    "#         for i in range(10):\n",
    "#             hour_str = '0'+str(i)\n",
    "\n",
    "for cl in df_list.keys():\n",
    "    print(cl,len(df_list[cl]))\n",
    "    df = pd.concat(df_list[cl])\n",
    "    df = df.round(2)\n",
    "    df.to_json(r'E:\\jupyter\\CTM\\data_processed\\state\\endhour_of_%s.json'%cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0a    99    AA    ja    sa\n",
      "18110700  0.12  0.25  0.03  0.02  0.10\n",
      "18110701  0.21  0.20  0.03  0.07  0.16\n",
      "18110702  0.13  0.19  0.01  0.05  0.13\n",
      "18110703  0.08  0.11  0.01  0.09  0.07\n",
      "18110800  0.13  0.25  0.03  0.02  0.11\n",
      "18110801  0.20  0.20  0.03  0.07  0.15\n",
      "18110802  0.13  0.18  0.02  0.09  0.12\n",
      "18110803  0.10  0.13  0.02  0.06  0.08\n",
      "18110900  0.12  0.27  0.03  0.02  0.10\n",
      "18110901  0.21  0.22  0.03  0.07  0.16\n",
      "18110902  0.14  0.20  0.02  0.06  0.12\n",
      "18110903  0.10  0.07  0.01  0.05  0.09\n",
      "18111000  0.12  0.27  0.03  0.01  0.10\n",
      "18111001  0.20  0.17  0.02  0.05  0.16\n",
      "18111002  0.14  0.18  0.02  0.09  0.13\n",
      "18111003  0.10  0.14  0.02  0.05  0.08\n",
      "18111100  0.12  0.26  0.03  0.02  0.10\n",
      "18111101  0.20  0.20  0.03  0.07  0.15\n",
      "18111102  0.10  0.05  0.02  0.08  0.11\n",
      "18111103  0.06  0.06  0.01  0.13  0.09\n"
     ]
    }
   ],
   "source": [
    "df1_json = pd.read_json(r'E:\\jupyter\\CTM\\data_processed\\state\\endhour_of_priority.json')\n",
    "print(df1_json.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
