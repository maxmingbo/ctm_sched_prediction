{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最ajob表出来，加入前7/14天 end_time start_time 等。\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "d_list= ['180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "          '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "          '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "          '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "          '180711', '180712', '180713', '180714', '180715']\n",
    "#47\n",
    "\n",
    "day_all = ['171211', '171212', '171213', '171214', '171215', '171216', '171217', '171218', '171219', '171220', \\\n",
    "           '171221', '171222', '171223', '171224', '171225', '171226', '171227', '171228', '171229', '171230', \\\n",
    "           '171231', '180101', '180102', '180104', '180105', '180106', '180107', '180108', '180109', '180110', \\\n",
    "           '180111', '180112', '180113', '180114', '180115', '180116', '180117', '180118', '180119', '180120', \\\n",
    "           '180121', '180122', '180123', '180124', '180125', '180126', '180127', '180128', '180129', '180130', '180131',\\\n",
    "           '180201', '180202', '180203', '180204', '180205', '180206', '180207', '180208', '180209', '180210',\\\n",
    "           '180211', '180212', '180213', '180214', '180215', '180216', '180217', '180218', '180219', '180220', \\\n",
    "           '180221', '180222', '180223', '180224', '180225', '180226', '180227', '180228', \\\n",
    "           '180301', '180302', '180303', '180304', '180305', '180306', '180307', '180308', '180309', '180310', \\\n",
    "           '180311', '180312', '180313', '180314', '180315', '180316', '180317', '180318', '180319', '180320',\\\n",
    "           '180321', '180322', '180323', '180324', '180325', '180326', '180327', '180328', '180329', '180330', '180331', \\\n",
    "           '180401', '180402', '180403', '180404', '180405', '180406', '180407', '180408', '180409', '180410', \\\n",
    "           '180411', '180412', '180413', '180414', '180415', '180416', '180417','180418', '180419', '180420',\\\n",
    "           '180421', '180422', '180423', '180424', '180425', '180426', '180427', '180428', '180429', '180430',\\\n",
    "           '180501', '180502', '180503', '180504', '180505', '180506', '180507', '180508', '180509', '180510',\\\n",
    "           '180511', '180512', '180513', '180514', '180515', '180516', '180517', '180518', '180519', '180520',\\\n",
    "           '180521', '180522', '180523', '180524', '180525', '180526', '180527', '180528', '180529', '180530',\\\n",
    "           '180531','180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "           '180711', '180712', '180713', '180714', '180715']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interval_mint(s):\n",
    "    if s is None:\n",
    "        return 0\n",
    "    value = int(s[0:5])\n",
    "    mytype = s[5:]\n",
    "    if mytype=='M':\n",
    "        value = value\n",
    "    elif mytype=='H':\n",
    "        value = value*60\n",
    "    return value\n",
    "\n",
    "def f_replace_oa(s):\n",
    "    return s.replace('oa','0a')\n",
    "\n",
    "def not_find_end_time(a):\n",
    "    if a==-1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_avg_run_start_mint(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    else:\n",
    "        h = s//10000\n",
    "        m = (s%10000)//100\n",
    "        s = s%100\n",
    "        return h*60+m+s/60\n",
    "f_sum_std = ('min','max','median','mean','std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180707\n",
      "180706\n",
      "180705\n",
      "180704\n",
      "180703\n",
      "180702\n",
      "180701\n",
      "180630\n",
      "180629\n",
      "180628\n",
      "180627\n",
      "180626\n",
      "180625\n",
      "180624\n",
      "180623\n",
      "180622\n",
      "180621\n",
      "180620\n",
      "180619\n",
      "180618\n",
      "180617\n"
     ]
    }
   ],
   "source": [
    "#for day in d_list:\n",
    "day = '180706'\n",
    "train_src = pd.read_csv('./ajob/ajob_%s.txt'%day,low_memory=False)\n",
    "day_i  = day_all.index(day)\n",
    "\n",
    "day_4 = int('20'+day+'040000')\n",
    "train_src = train_src[train_src.order_time<day_4]\n",
    "train_src = train_src[train_src.avg_start_time.notnull()]\n",
    "train_src = train_src[train_src.avg_start_time<400000]\n",
    "train_src = train_src[train_src.order==day]\n",
    "\n",
    "\n",
    "\n",
    "train_src.drop('confirm_flag',axis=1,inplace=True)\n",
    "train_src.drop('job_id',axis=1,inplace=True)\n",
    "train_src.drop('from_time',axis=1,inplace=True)\n",
    "train_src.drop('next_time',axis=1,inplace=True)\n",
    "train_src.drop('to_time',axis=1,inplace=True)\n",
    "train_src.drop('delete_flag',axis=1,inplace=True)\n",
    "train_src.drop('rerun_counter',axis=1,inplace=True)\n",
    "train_src.drop('prev_odate_rerun_counter',axis=1,inplace=True)\n",
    "train_src.drop('cpu_time',axis=1,inplace=True)\n",
    "train_src.drop('cpu_id',axis=1,inplace=True)\n",
    "\n",
    "#train_src['nodegroup']= train_src['nodegroup'].fillna('none')\n",
    "#train_src['priority'] = train_src['priority'].apply(f_replace_oa)\n",
    "#train_src['interval'] = train_src['interval'].apply(get_interval_mint)\n",
    "#train_src['avg_runtime'] = train_src['avg_runtime'].apply(get_avg_run_stat_mint)\n",
    "train_src['avg_start_time'] = train_src['avg_start_time'].apply(get_avg_run_start_mint)\n",
    "\n",
    "\n",
    "def get_job_n_day_before_start_time(n,job_list):\n",
    "\n",
    "        day = day_all[day_i - n]\n",
    "        print(day)\n",
    "        day_begain = int('20'+day+'000000')\n",
    "        day_8 = int('20'+day+'040000') #实例化要在8点前，排除手工追数情况;\n",
    "        if n ==0:\n",
    "            df =train_src\n",
    "        else:\n",
    "            df = pd.read_csv('./ajob/ajob_%s.txt'%day,low_memory=False)\n",
    "        df = df[df.end_time.notnull()]\n",
    "        #print(df.shape)\n",
    "        df = df[(df.order_time>day_begain)&(df.order_time<day_8)]\n",
    "        #print(df.shape)\n",
    "\n",
    "\n",
    "        dat_start = datetime.datetime.strptime(str(day_begain),'%Y%m%d%H%M%S')\n",
    "\n",
    "        def f_get_mint_bef(x):\n",
    "            dat_t = datetime.datetime.strptime(str(x),'%Y%m%d%H%M%S')\n",
    "            dt = (dat_t-dat_start).total_seconds()//60\n",
    "            return dt\n",
    "\n",
    "        #df['end_time'] = df['end_time'].apply(int).apply(f_get_mint_bef)\n",
    "        df['start_time'] = df['start_time'].apply(int).apply(f_get_mint_bef)\n",
    "\n",
    "        df_start = df[['job_name','start_time']]\n",
    "        #df_end = df[['job_name','end_time']]\n",
    "\n",
    "        df_start_dict = df_start.groupby('job_name').start_time.min().T.to_dict()\n",
    "        #df_end_dict = df_end.groupby('job_name').end_time.min().T.to_dict()\n",
    "\n",
    "        start_not_findjob = list(set(job_list)-set(df_start_dict.keys()))\n",
    "        #end_not_findjob = list(set(job_list)-set(df_end_dict.keys()))\n",
    "\n",
    "        for job in start_not_findjob:\n",
    "            df_start_dict[job] = -1\n",
    "#         for job in end_not_findjob:\n",
    "#             df_end_dict[job] = -1\n",
    "\n",
    "        return job_list.apply(lambda x:df_start_dict[x])\n",
    "\n",
    "    #统计前 n  天日期 完成时间\n",
    "for k in range(1,22,1):\n",
    "    #print(k)\n",
    "    train_src['day_%d_bef_start_time'%k] = get_job_n_day_before_start_time(k,train_src['job_name'])\n",
    "    \n",
    "\n",
    "day_1_k_bef_start_time = ['day_%d_bef_start_time'%k for k in range(1,40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 43.7189086389 33.9196065701\n",
      "8 40.2581004384 30.8136799599\n",
      "9 39.3635363322 30.3198409456\n",
      "10 37.1951406509 28.2925506874\n",
      "11 35.1951590842 26.165392551\n",
      "12 32.8071764487 23.5687342428\n",
      "13 29.7813919095 20.1767509526\n",
      "14 27.5903518209 17.6855692563\n",
      "15 27.0374005143 17.0162157502\n",
      "16 27.5116339824 17.4152300142\n",
      "17 25.9521201032 15.7358529789\n",
      "18 25.0440302368 14.5582739862\n",
      "19 24.2004891801 13.5144579052\n",
      "20 23.8573758849 12.9250017215\n",
      "21 23.7159611661 12.4528427594\n"
     ]
    }
   ],
   "source": [
    "day_int = int(day)\n",
    "train_src = train_src[train_src.odate==day_int]\n",
    "for i in range(7,22):\n",
    "    day_1_k_sum = day_1_k_bef_start_time[:i]\n",
    "    train_src['day_1_k_avg_start_time'] = train_src[day_1_k_sum].apply('mean',axis=1)\n",
    "    train_src['day_k_start_time_min'] = train_src[day_1_k_sum].apply(min, axis=1)\n",
    "    train_src['day_k_no_start_time'] = train_src['day_k_start_time_min'].apply(not_find_end_time)\n",
    "    \n",
    "    train_src['avg_1_k_sub_avg'] = train_src[['day_1_k_avg_start_time','avg_start_time']].apply(lambda x:abs(x[1]-x[0]),axis=1)\n",
    "    \n",
    "    train_src = train_src.round(2)\n",
    "    \n",
    "    print(i,train_src['avg_1_k_sub_avg'].mean(),train_src[train_src['day_k_no_start_time']==0]['avg_1_k_sub_avg'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7 43.7188989575 33.9195944998\n",
    "8 40.2581004384 30.8136799599\n",
    "9 39.3635363322 30.3198409456\n",
    "10 37.1951406509 28.2925506874\n",
    "11 35.1951590842 26.165392551\n",
    "12 32.8071764487 23.5687342428\n",
    "13 29.7813919095 20.1767509526\n",
    "14 27.5903518209 17.6855692563\n",
    "15 27.0374005143 17.0162157502\n",
    "16 27.5116339824 17.4152300142\n",
    "17 25.9521201032 15.7358529789\n",
    "18 25.0440302368 14.5582739862\n",
    "19 24.2004891801 13.5144579052\n",
    "20 23.8573758849 12.9250017215\n",
    "21 23.7159611661 12.4528427594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180708\n",
      "180707\n",
      "180706\n",
      "180705\n",
      "180704\n",
      "180703\n",
      "180702\n",
      "180701\n",
      "180630\n",
      "180629\n",
      "180628\n",
      "180627\n",
      "180626\n",
      "180625\n",
      "180624\n",
      "180623\n",
      "180622\n",
      "180621\n",
      "180620\n",
      "180619\n"
     ]
    }
   ],
   "source": [
    "#for day in d_list:\n",
    "day = '180710'\n",
    "train_src = pd.read_csv('./ajob/ajob_%s.txt'%day,low_memory=False)\n",
    "day_i  = day_all.index(day)\n",
    "\n",
    "day_4 = int('20'+day+'040000')\n",
    "train_src = train_src[train_src.order_time<day_4]\n",
    "train_src = train_src[train_src.avg_start_time.notnull()]\n",
    "train_src = train_src[train_src.avg_start_time<400000]\n",
    "train_src = train_src[train_src.odate==int(day)]\n",
    "\n",
    "\n",
    "\n",
    "train_src.drop('confirm_flag',axis=1,inplace=True)\n",
    "train_src.drop('job_id',axis=1,inplace=True)\n",
    "train_src.drop('from_time',axis=1,inplace=True)\n",
    "train_src.drop('next_time',axis=1,inplace=True)\n",
    "train_src.drop('to_time',axis=1,inplace=True)\n",
    "train_src.drop('delete_flag',axis=1,inplace=True)\n",
    "train_src.drop('rerun_counter',axis=1,inplace=True)\n",
    "train_src.drop('prev_odate_rerun_counter',axis=1,inplace=True)\n",
    "train_src.drop('cpu_time',axis=1,inplace=True)\n",
    "train_src.drop('cpu_id',axis=1,inplace=True)\n",
    "\n",
    "#train_src['nodegroup']= train_src['nodegroup'].fillna('none')\n",
    "#train_src['priority'] = train_src['priority'].apply(f_replace_oa)\n",
    "#train_src['interval'] = train_src['interval'].apply(get_interval_mint)\n",
    "#train_src['avg_runtime'] = train_src['avg_runtime'].apply(get_avg_run_stat_mint)\n",
    "train_src['avg_start_time'] = train_src['avg_start_time'].apply(get_avg_run_start_mint)\n",
    "\n",
    "\n",
    "def get_job_n_day_before_start_time(n,job_list):\n",
    "\n",
    "        day = day_all[day_i - n]\n",
    "        print(day)\n",
    "        day_begain = int('20'+day+'000000')\n",
    "        day_8 = int('20'+day+'040000') #实例化要在8点前，排除手工追数情况;\n",
    "        if n ==0:\n",
    "            df =train_src\n",
    "        else:\n",
    "            df = pd.read_csv('./ajob/ajob_%s.txt'%day,low_memory=False)\n",
    "        df = df[df.end_time.notnull()]\n",
    "        #print(df.shape)\n",
    "        df = df[(df.order_time>day_begain)&(df.order_time<day_8)]\n",
    "        #print(df.shape)\n",
    "\n",
    "\n",
    "        dat_start = datetime.datetime.strptime(str(day_begain),'%Y%m%d%H%M%S')\n",
    "\n",
    "        def f_get_mint_bef(x):\n",
    "            dat_t = datetime.datetime.strptime(str(x),'%Y%m%d%H%M%S')\n",
    "            dt = (dat_t-dat_start).total_seconds()//60\n",
    "            return dt\n",
    "\n",
    "        #df['end_time'] = df['end_time'].apply(int).apply(f_get_mint_bef)\n",
    "        df['start_time'] = df['start_time'].apply(int).apply(f_get_mint_bef)\n",
    "\n",
    "        df_start = df[['job_name','start_time']]\n",
    "        #df_end = df[['job_name','end_time']]\n",
    "\n",
    "        df_start_dict = df_start.groupby('job_name').start_time.min().T.to_dict()\n",
    "        #df_end_dict = df_end.groupby('job_name').end_time.min().T.to_dict()\n",
    "\n",
    "        start_not_findjob = list(set(job_list)-set(df_start_dict.keys()))\n",
    "        #end_not_findjob = list(set(job_list)-set(df_end_dict.keys()))\n",
    "\n",
    "        for job in start_not_findjob:\n",
    "            df_start_dict[job] = -1\n",
    "#         for job in end_not_findjob:\n",
    "#             df_end_dict[job] = -1\n",
    "\n",
    "        return job_list.apply(lambda x:df_start_dict[x])\n",
    "\n",
    "    #统计前 n  天日期 完成时间\n",
    "for k in range(2,22):\n",
    "    #print(k)\n",
    "    train_src['day_%d_bef_start_time'%k] = get_job_n_day_before_start_time(k,train_src['job_name'])\n",
    "    \n",
    "\n",
    "day_1_k_bef_start_time = ['day_%d_bef_start_time'%k for k in range(2,22)]\n",
    "\n",
    "train_src['avg_start_time'] = train_src['avg_start_time'].apply(lambda x:x*21)\n",
    "train_src['day_2_21_bef_start_time_sum'] = train_src[day_1_k_bef_start_time].apply(sum,axis=1)\n",
    "\n",
    "train_src['day_1_bef_start_int'] = train_src[['avg_start_time','day_2_21_bef_start_time_sum']].apply(lambda x:abs(x[0]-x[1]),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "day_bef = day_all[day_i - 1]\n",
    "day_bef_start = datetime.datetime.strptime(str('20'+day_bef+'000000'),'%Y%m%d%H%M%S')\n",
    "\n",
    "def f_cnv_int_to_time(int_t):\n",
    "    \n",
    "    return((day_bef_start+datetime.timedelta(minutes=int_t)).strftime('%Y%m%d%H%M%S'))\n",
    "    \n",
    "train_src['day_1_bef_start_time'] = train_src['day_1_bef_start_int'].apply(f_cnv_int_to_time)\n",
    "\n",
    "train_src_save = train_src[['job_name','day_1_bef_start_time','day_1_bef_start_int']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'180709'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_bef_df = train_src = pd.read_csv('./ajob/ajob_%s.txt'%day_bef,low_memory=False)\n",
    "\n",
    "day_bef_df = day_bef_df[['order_id','job_name','v_date','avg_runtime','start_time','end_time']]\n",
    "\n",
    "day_bef_df =day_bef_df.merge(train_src_save,on=['job_name'],how='left')\n",
    "\n",
    "day_bef_df = day_bef_df[day_bef_df.start_time.notnull()]\n",
    "\n",
    "day_bef_df['start_time'] =day_bef_df['start_time'].apply(int)\n",
    "\n",
    "day_bef_df = day_bef_df.round(2)\n",
    "#day_bef_df.to_csv('submit_%s.csv'%day_bef,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'meam'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-9181b7080cc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mday_bef_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mday_bef_sum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'start_time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'day_1_bef_start_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mday_bef_sum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_time_del\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3612\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3613\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3614\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3616\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'meam'"
     ]
    }
   ],
   "source": [
    "def get_time_del(x):\n",
    "    d1 = datetime.datetime.strptime(str(x[0]),'%Y%m%d%H%M%S')\n",
    "    d2 = datetime.datetime.strptime(str(x[1]),'%Y%m%d%H%M%S')\n",
    "    dt = (d2-d1).total_seconds()//60\n",
    "    return dt\n",
    "day_bef_sum = day_bef_df[day_bef_df.start_time.notnull()]\n",
    "day_bef_sum = day_bef_sum[day_bef_sum.day_1_bef_start_time.notnull()]\n",
    "\n",
    "day_bef_sum = day_bef_sum[['start_time','day_1_bef_start_time']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.23002752883025"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(day_bef_sum.apply(get_time_del,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "d_list= [  '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "          '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180625   62.7709215982\n",
      "180626   82.1206685251\n",
      "180627   70.6067584775\n",
      "180628   85.5125416822\n",
      "180629   123.84218447\n",
      "180630   117.236535013\n",
      "180701   99.6965106969\n",
      "180702   150.353861691\n",
      "180703   102.522794463\n",
      "180704   70.6125006451\n",
      "180705   93.2382138143\n",
      "180706   101.294197111\n",
      "180707   126.65772879\n",
      "180708   67.5168117995\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for day in d_list:\n",
    "    print(day,end=' ')\n",
    "    train_gen = pd.read_csv('./ajob/ajob_1_%s.csv'%day)\n",
    "    \n",
    "    #x = train_gen[cols_train]\n",
    "    #y = train_gen['day_0_bef_end_time']\n",
    "    \n",
    "    train_gen = train_gen[(train_gen.day_0_bef_end_time>240)&(train_gen.day_0_bef_end_time<1530)&(train_gen.day_1_bef_start_time.notnull())]\n",
    "    train_gen['sub_valid'] = train_gen[['day_0_bef_end_time','day_1_bef_start_time','avg_runtime']].apply(lambda x:abs(x[0]-x[1]-x[2]),axis=1)\n",
    "    print(' ',train_gen['sub_valid'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
