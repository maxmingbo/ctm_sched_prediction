{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#这里的代码是使用lightgbm 对预测dt的特征做特征重要性排序。\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "train_list = ['180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "          '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "          '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "          '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "          '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015']\n",
    "\n",
    "valid_list = ['181016', '181017', '181018', '181019', '181020', '181021']\n",
    "\n",
    "# test_list = ['180709', '180710', '180711', '180712', '180713', '180714', '180715']\n",
    "\n",
    "# d_list= ['180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "#           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "#           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "#           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "#           '180711', '180712', '180713', '180714', '180715',\\\n",
    "#          '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725', \\\n",
    "#           '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804', \\\n",
    "#           '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "#           '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822',\\\n",
    "#           '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "#           '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "#           '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "#           '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "#           '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "#           '181016', '181017', '181018', '181019', '181020', '181021']\n",
    "\n",
    "\n",
    "day_all = ['180501', '180502', '180503', '180504', '180505', '180506', '180507', '180508', '180509', '180510',\\\n",
    "           '180511', '180512', '180513', '180514', '180515', '180516', '180517', '180518', '180519', '180520',\\\n",
    "           '180521', '180522', '180523', '180524', '180525', '180526', '180527', '180528', '180529', '180530',\\\n",
    "           '180531','180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "           '180711', '180712', '180713', '180714', '180715',\\\n",
    "           '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725',\\\n",
    "           '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804',\\\n",
    "           '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "           '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822', \\\n",
    "            '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "           '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "           '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "            '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "           '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "           '181016', '181017', '181018', '181019', '181020', '181021','181022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义截取函数\n",
    "def over_data_do(s):\n",
    "    if s<0:\n",
    "        return 0\n",
    "    elif s> 2880:\n",
    "        return 2880\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 2\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 3\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 4\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 5\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 6\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 7\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 8\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 9\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 10\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 11\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 12\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 13\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 14\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 15\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 16\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 17\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 18\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 19\n",
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 "
     ]
    }
   ],
   "source": [
    "\n",
    " #选取第几轮数据切片\n",
    "for n_i in range(1,20):\n",
    "    train_df = []\n",
    "    print(n_i)\n",
    "    for day in train_list:\n",
    "        print(day,end=' ')   \n",
    "        day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\train\\train_%s_edt.csv'%day)\n",
    "\n",
    "        #day_all_data = day_all_data[day_all_data.end_time.notnull()]\n",
    "\n",
    "        #过滤结束日期超过2天的\n",
    "        day_after_2 = day_all[day_all.index(day)+1]\n",
    "        day_after_2_int = int('20'+day_after_2+'235959')\n",
    "        day_all_data = day_all_data[day_all_data.end_time<day_after_2_int]\n",
    "        day_all_data = day_all_data[day_all_data.end_time.notnull()]\n",
    "\n",
    "        round_len = day_all_data.shape[0]//20\n",
    "        train_df.append(day_all_data[n_i*round_len:(n_i+1)*round_len])\n",
    "\n",
    "    train = pd.concat(train_df, ignore_index=True)\n",
    "\n",
    "    train.to_csv('./data_edt_train/edt_split_%d.csv'%n_i,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181016 181017 181018 181019 181020 181021 (357701, 215)\n",
      "(166703, 215)\n"
     ]
    }
   ],
   "source": [
    "# 和下面的代码功能同\n",
    "\n",
    "n_i = 3\n",
    "train = pd.read_csv('./data_edt_train/edt_split_%d.csv'%n_i)\n",
    "\n",
    "valid_df = []\n",
    "for day in valid_list:\n",
    "    print(day,end=' ')\n",
    "    day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\train\\train_%s_edt.csv'%day)\n",
    "    #day_all_data = day_all_data[day_all_data.end_time.notnull()]\n",
    "    day_after_2 = day_all[day_all.index(day)+1]\n",
    "    day_after_2_int = int('20'+day_after_2+'235959')\n",
    "    day_all_data = day_all_data[day_all_data.end_time<day_after_2_int]\n",
    "    \n",
    "    valid_df.append(day_all_data.sample(frac=0.2))\n",
    "    \n",
    "valid = pd.concat(valid_df, ignore_index=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 181016 181017 181018 181019 181020 181021 "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ad3ba88b69a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mday_all_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'E:\\jupyter\\CTM\\data_train\\train\\train_%s_edt.csv'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m#day_all_data = day_all_data[day_all_data.end_time.notnull()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mday_after_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mday_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mday_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mday_after_2_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'20'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mday_after_2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'000000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mday_all_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mday_all_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mday_all_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_time\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mday_after_2_int\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#读取数据 按天\n",
    "\n",
    "# 划分训练集， 验证集 测试集\n",
    "\n",
    "train_df = []\n",
    "n_i = 1  #选取第几轮数据切片\n",
    "for day in train_list:\n",
    "    print(day,end=' ')   \n",
    "    day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\train\\train_%s_edt.csv'%day)\n",
    "    \n",
    "    #day_all_data = day_all_data[day_all_data.end_time.notnull()]\n",
    "    \n",
    "    #过滤结束日期超过2天的\n",
    "    day_after_2 = day_all[day_all.index(day)+1]\n",
    "    day_after_2_int = int('20'+day_after_2+'235959')\n",
    "    day_all_data = day_all_data[day_all_data.end_time<day_after_2_int]\n",
    "    day_all_data = day_all_data[day_all_data.end_time.notnull()]\n",
    "    \n",
    "    round_len = day_all_data.shape[0]//14\n",
    "    train_df.append(day_all_data[n_i*round_len:(n_i+1)*round_len])\n",
    "    \n",
    "train = pd.concat(train_df, ignore_index=True)\n",
    "\n",
    "train.to_csv('./data_edt_train/edt_split_%d.csv'%n_i,index=False)\n",
    "\n",
    "valid_df = []\n",
    "for day in valid_list:\n",
    "    print(day,end=' ')\n",
    "    day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\train\\train_%s_edt.csv'%day)\n",
    "    #day_all_data = day_all_data[day_all_data.end_time.notnull()]\n",
    "    day_after_2 = day_all[day_all.index(day)+1]\n",
    "    day_after_2_int = int('20'+day_after_2+'235959')\n",
    "    day_all_data = day_all_data[day_all_data.end_time<day_after_2_int]\n",
    "    \n",
    "    valid_df.append(day_all_data.sample(frac=0.2))\n",
    "    \n",
    "valid = pd.concat(valid_df, ignore_index=True)\n",
    "\n",
    "# test_df = []\n",
    "\n",
    "# for day in test_list:\n",
    "#     print(day,end=' ')   \n",
    "#     day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\valid_data\\train/train_%s_edt.csv'%day)\n",
    "#     day_all_data = day_all_data[day_all_data.end_time.notnull()]\n",
    "#     test_df.append(day_all_data)\n",
    "    \n",
    "# test = pd.concat(test_df, ignore_index=True)\n",
    "\n",
    "#空值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(321930, 206)\n",
      "(35771, 206)\n",
      "(166703, 206)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#过滤训练不需要的数据字段\n",
    "cols_train =[clm for clm in valid.columns if clm not in ['order_id','job_name','v_date','order_d','from_time_1000_start',\\\n",
    "                                                            'start_time','end_time','order_id','job_name','day_0_bef_start_time',\\\n",
    "                                                            'day_0_bef_end_time','day_bef_0_dt']]\n",
    "\n",
    "\n",
    "valid_x = valid[cols_train]\n",
    "valid_y = valid['day_0_bef_end_time']\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(train[cols_train],train['day_0_bef_end_time'],random_state=33,test_size=0.1)\n",
    "\n",
    "train_y = train_y.fillna(train_y.mean())\n",
    "valid_y = valid_y.fillna(valid_y.mean())\n",
    "test_y = test_y.fillna(test_y.mean())  \n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(valid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\tvalid_0's l2: 130509\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 114246\n",
      "[3]\tvalid_0's l2: 100763\n",
      "[4]\tvalid_0's l2: 89778.6\n",
      "[5]\tvalid_0's l2: 80626.8\n",
      "[6]\tvalid_0's l2: 73181.3\n",
      "[7]\tvalid_0's l2: 67069.6\n",
      "[8]\tvalid_0's l2: 61919.6\n",
      "[9]\tvalid_0's l2: 57680.2\n",
      "[10]\tvalid_0's l2: 54145.3\n",
      "[11]\tvalid_0's l2: 51102.5\n",
      "[12]\tvalid_0's l2: 48577.5\n",
      "[13]\tvalid_0's l2: 46468.9\n",
      "[14]\tvalid_0's l2: 44630.7\n",
      "[15]\tvalid_0's l2: 43069.6\n",
      "[16]\tvalid_0's l2: 41700.1\n",
      "[17]\tvalid_0's l2: 40535.3\n",
      "[18]\tvalid_0's l2: 39510.2\n",
      "[19]\tvalid_0's l2: 38658.1\n",
      "[20]\tvalid_0's l2: 37857.9\n",
      "[21]\tvalid_0's l2: 37131.5\n",
      "[22]\tvalid_0's l2: 36521.1\n",
      "[23]\tvalid_0's l2: 35892\n",
      "[24]\tvalid_0's l2: 35390.5\n",
      "[25]\tvalid_0's l2: 34890.7\n",
      "[26]\tvalid_0's l2: 34449.7\n",
      "[27]\tvalid_0's l2: 34080.7\n",
      "[28]\tvalid_0's l2: 33721.3\n",
      "[29]\tvalid_0's l2: 33382.4\n",
      "[30]\tvalid_0's l2: 33076.5\n",
      "[31]\tvalid_0's l2: 32834.7\n",
      "[32]\tvalid_0's l2: 32544.9\n",
      "[33]\tvalid_0's l2: 32337.5\n",
      "[34]\tvalid_0's l2: 32174.5\n",
      "[35]\tvalid_0's l2: 31964.8\n",
      "[36]\tvalid_0's l2: 31719.7\n",
      "[37]\tvalid_0's l2: 31494.7\n",
      "[38]\tvalid_0's l2: 31277.9\n",
      "[39]\tvalid_0's l2: 31079.5\n",
      "[40]\tvalid_0's l2: 30832.7\n",
      "[41]\tvalid_0's l2: 30653.1\n",
      "[42]\tvalid_0's l2: 30491.9\n",
      "[43]\tvalid_0's l2: 30355.2\n",
      "[44]\tvalid_0's l2: 30194.1\n",
      "[45]\tvalid_0's l2: 30026.9\n",
      "[46]\tvalid_0's l2: 29897.4\n",
      "[47]\tvalid_0's l2: 29769.5\n",
      "[48]\tvalid_0's l2: 29620.3\n",
      "[49]\tvalid_0's l2: 29467\n",
      "[50]\tvalid_0's l2: 29351\n",
      "[51]\tvalid_0's l2: 29241.4\n",
      "[52]\tvalid_0's l2: 29135\n",
      "[53]\tvalid_0's l2: 29066.6\n",
      "[54]\tvalid_0's l2: 28980.6\n",
      "[55]\tvalid_0's l2: 28876.4\n",
      "[56]\tvalid_0's l2: 28805.7\n",
      "[57]\tvalid_0's l2: 28697\n",
      "[58]\tvalid_0's l2: 28460.8\n",
      "[59]\tvalid_0's l2: 28383.1\n",
      "[60]\tvalid_0's l2: 28187.3\n",
      "[61]\tvalid_0's l2: 28092.7\n",
      "[62]\tvalid_0's l2: 28014.9\n",
      "[63]\tvalid_0's l2: 27934.9\n",
      "[64]\tvalid_0's l2: 27802.5\n",
      "[65]\tvalid_0's l2: 27727.5\n",
      "[66]\tvalid_0's l2: 27633.4\n",
      "[67]\tvalid_0's l2: 27563.2\n",
      "[68]\tvalid_0's l2: 27489.5\n",
      "[69]\tvalid_0's l2: 27430.2\n",
      "[70]\tvalid_0's l2: 27343.5\n",
      "[71]\tvalid_0's l2: 27276.3\n",
      "[72]\tvalid_0's l2: 27225.5\n",
      "[73]\tvalid_0's l2: 27175.4\n",
      "[74]\tvalid_0's l2: 27124.9\n",
      "[75]\tvalid_0's l2: 27048.4\n",
      "[76]\tvalid_0's l2: 26971.6\n",
      "[77]\tvalid_0's l2: 26861\n",
      "[78]\tvalid_0's l2: 26805.2\n",
      "[79]\tvalid_0's l2: 26764.3\n",
      "[80]\tvalid_0's l2: 26707.1\n",
      "[81]\tvalid_0's l2: 26592.8\n",
      "[82]\tvalid_0's l2: 26512.8\n",
      "[83]\tvalid_0's l2: 26446.6\n",
      "[84]\tvalid_0's l2: 26379.6\n",
      "[85]\tvalid_0's l2: 26343.7\n",
      "[86]\tvalid_0's l2: 26274.1\n",
      "[87]\tvalid_0's l2: 26212.4\n",
      "[88]\tvalid_0's l2: 26144.9\n",
      "[89]\tvalid_0's l2: 26100.6\n",
      "[90]\tvalid_0's l2: 26047.2\n",
      "[91]\tvalid_0's l2: 26010.2\n",
      "[92]\tvalid_0's l2: 25947.4\n",
      "[93]\tvalid_0's l2: 25882.2\n",
      "[94]\tvalid_0's l2: 25850.7\n",
      "[95]\tvalid_0's l2: 25805.7\n",
      "[96]\tvalid_0's l2: 25754.8\n",
      "[97]\tvalid_0's l2: 25696.5\n",
      "[98]\tvalid_0's l2: 25659.5\n",
      "[99]\tvalid_0's l2: 25634.4\n",
      "[100]\tvalid_0's l2: 25597.3\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l2: 25597.3\n",
      "Save model...\n",
      "Start predicting...\n",
      "The MAE of prediction train_data is: 91.7078200717\n",
      "The MAE of prediction valid_data is: 86.6426869845\n",
      "The MSE of prediction train_data is: 23181.5505251\n"
     ]
    }
   ],
   "source": [
    "# lightgbm 算法预测\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "y_train = train_y.values\n",
    "y_test = test_y.values\n",
    "\n",
    "X_train = train_x.values\n",
    "X_test = test_x.values\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train,silent=True)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {'task': 'train',\n",
    "   'boosting_type': 'gbdt',\n",
    "   'objective': 'regression',\n",
    "   'metric':  'mse',\n",
    "   'num_leaves': 2**7,\n",
    "   'learning_rate': 0.1,\n",
    "   'feature_fraction': 0.9,\n",
    "   'bagging_fraction': 0.8,\n",
    "   'bagging_freq': 5,\n",
    "   'verbose': 50,\n",
    "    'verbose_eval':50}\n",
    "  \n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "print('Save model...')\n",
    "\n",
    "# save model to file\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(gbm,'edt_gbm.pkl')\n",
    "clf = joblib.load(\"edt_gbm.pkl\")\n",
    "\n",
    "gbm.save_model('lightgbm_model_edt.txt')\n",
    "print('Start predicting...')\n",
    "\n",
    "\n",
    "# predict\n",
    "\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "vlid_pred = gbm.predict(valid_x, num_iteration=gbm.best_iteration)\n",
    "#clf_pred = gbm.predict(valid_x, num_iteration=gbm.best_iteration)\n",
    "# eval print(y_pred)\n",
    "print('The MAE of prediction train_data is:', mean_absolute_error(y_test, y_pred))\n",
    "print('The MAE of prediction valid_data is:', mean_absolute_error(valid_y, vlid_pred))\n",
    "# print('The mean_absolute_error of prediction valid_data is:', mean_absolute_error(valid_y, clf_pred))\n",
    "\n",
    "print('The MSE of prediction train_data is:', mean_squared_error(valid_y, vlid_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The MAE of prediction train_data is: 91.7078200717\n",
    "The MAE of prediction valid_data is: 86.6426869845\n",
    "The MSE of prediction train_data is: 23181.5505251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### 特征选择   保存模型特征重要性\n",
    "df = pd.DataFrame(train_x.columns.tolist(), columns=['feature'])\n",
    "df['importance']=list(gbm.feature_importance())                           # 特征分数\n",
    "df = df.sort_values(by='importance',ascending=False)                      # 特征排序\n",
    "df.to_csv(\"./edt_feature_score.csv\",index=None,encoding='gbk')  # 保存分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('edt_feature_score.csv')\n",
    "features = features['feature'][:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm 算法预测\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "\n",
    "y_train = train_y.values\n",
    "y_test = test_y.values\n",
    "\n",
    "X_train = train_x.values\n",
    "X_test = test_x.values\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train,silent=True)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {'task': 'train',\n",
    "   'boosting_type': 'gbdt',\n",
    "   'objective': 'regression',\n",
    "   'metric':  'mse',\n",
    "   'num_leaves': 2**7,\n",
    "   'learning_rate': 0.1,\n",
    "   'feature_fraction': 0.9,\n",
    "   'bagging_fraction': 0.8,\n",
    "   'bagging_freq': 5,\n",
    "   'verbose': 50,\n",
    "    'verbose_eval':50}\n",
    "  \n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "print('Save model...')\n",
    "\n",
    "# save model to file\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(gbm,'edt_gbm.pkl')\n",
    "clf = joblib.load(\"edt_gbm.pkl\")\n",
    "\n",
    "gbm.save_model('lightgbm_model_edt.txt')\n",
    "print('Start predicting...')\n",
    "\n",
    "\n",
    "# predict\n",
    "\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "vlid_pred = gbm.predict(valid_x, num_iteration=gbm.best_iteration)\n",
    "#clf_pred = gbm.predict(valid_x, num_iteration=gbm.best_iteration)\n",
    "# eval print(y_pred)\n",
    "print('The MAE of prediction train_data is:', mean_absolute_error(y_test, y_pred))\n",
    "print('The MAE of prediction valid_data is:', mean_absolute_error(valid_y, vlid_pred))\n",
    "# print('The mean_absolute_error of prediction valid_data is:', mean_absolute_error(valid_y, clf_pred))\n",
    "\n",
    "print('The MSE of prediction valid_data is:', mean_squared_error(valid_y, vlid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [71541, 35771]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-40207492cf30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mvlid_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The MAE of prediction train_data is:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The MAE of prediction valid_data is:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvlid_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#print('The mean_absolute_error of prediction valid_data is:', mean_absolute_error(valid_y, clf_pred))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \"\"\"\n\u001b[0;32m    169\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 170\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    171\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n\u001b[0;32m    172\u001b[0m                                weights=sample_weight, axis=0)\n",
      "\u001b[1;32mc:\\program files\\python3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [71541, 35771]"
     ]
    }
   ],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "dtr = xgb.XGBRegressor(max_depth=8, learning_rate=0.1)\n",
    "\n",
    "\n",
    "# train_x,test_x,train_y,test_y\n",
    "dtr.fit(train_x[features],train_y)\n",
    "\n",
    "y_pred = dtr.predict(test_x[features])\n",
    "vlid_pred = dtr.predict(valid_x[features])\n",
    "\n",
    "print('The MAE of prediction train_data is:', mean_absolute_error(test_y, y_pred))\n",
    "print('The MAE of prediction valid_data is:', mean_absolute_error(valid_y, vlid_pred))\n",
    "#print('The mean_absolute_error of prediction valid_data is:', mean_absolute_error(valid_y, clf_pred))\n",
    "\n",
    "print('The MSE of prediction valid_data is:', mean_squared_error(valid_y, vlid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of prediction train_data is: 85.7944480783\n",
      "The MAE of prediction valid_data is: 85.1375072346\n",
      "The MSE of prediction valid_data is: 23907.0302866\n"
     ]
    }
   ],
   "source": [
    "print('The MAE of prediction train_data is:', mean_absolute_error(test_y, y_pred))\n",
    "print('The MAE of prediction valid_data is:', mean_absolute_error(valid_y, vlid_pred))\n",
    "#print('The mean_absolute_error of prediction valid_data is:', mean_absolute_error(valid_y, clf_pred))\n",
    "\n",
    "print('The MSE of prediction valid_data is:', mean_squared_error(valid_y, vlid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of prediction train_data is: 74.7287435372\n",
      "The MAE of prediction valid_data is: 85.8226865694\n",
      "The MSE of prediction valid_data is: 23641.0085073\n"
     ]
    }
   ],
   "source": [
    "dtr = xgb.XGBRegressor(max_depth=8, learning_rate=0.1)\n",
    "所有特征\n",
    "The MAE of prediction train_data is: 85.0395749341\n",
    "The MAE of prediction valid_data is: 85.0483190648\n",
    "The MSE of prediction valid_data is: 23211.1046788\n",
    "max_depth=9\n",
    "The MAE of prediction train_data is: 79.2312313776\n",
    "The MAE of prediction valid_data is: 84.0364825932\n",
    "The MSE of prediction valid_data is: 22906.597829\n",
    "max_depth=10\n",
    "The MAE of prediction train_data is: 74.7287435372\n",
    "The MAE of prediction valid_data is: 85.8226865694\n",
    "The MSE of prediction valid_data is: 23641.0085073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = xgb.XGBRegressor(max_depth=8, learning_rate=0.1)\n",
    "\n",
    "100\n",
    "The MAE of prediction train_data is: 84.8834261761\n",
    "The MAE of prediction valid_data is: 87.1222425463\n",
    "The MSE of prediction valid_data is: 23468.1188846\n",
    "120\n",
    "The MAE of prediction train_data is: 84.9453742738\n",
    "The MAE of prediction valid_data is: 90.8959669376\n",
    "The MSE of prediction valid_data is: 24453.9947591\n",
    "80\n",
    "The MAE of prediction train_data is: 85.1988766365\n",
    "The MAE of prediction valid_data is: 85.5486905383\n",
    "The MSE of prediction valid_data is: 23312.3482064\n",
    "70    \n",
    "The MAE of prediction train_data is: 85.4171723916\n",
    "The MAE of prediction valid_data is: 85.4214605148\n",
    "The MSE of prediction valid_data is: 23688.5333861"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
