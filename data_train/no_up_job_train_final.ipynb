{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "train_list = ['180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "          '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "          '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "          '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "          '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "           '181016', '181017', '181018', '181019', '181020', '181021',\\\n",
    "           '181022', '181023', '181024', '181025', '181026', '181027', '181028', '181029','181101',\\\n",
    "             '181030','181031','181101' ,'181102','181103','181104']\n",
    "\n",
    "valid_list = ['181105', '181106', '181107', '181108', '181109','181110','181111']\n",
    "\n",
    "\n",
    "day_all = ['180531','180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610',\\\n",
    "           '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620',\\\n",
    "           '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630',\\\n",
    "           '180701', '180702', '180703', '180704', '180705', '180706', '180707', '180708', '180709', '180710', \\\n",
    "           '180711', '180712', '180713', '180714', '180715',\\\n",
    "           '180716', '180717', '180718', '180719', '180720', '180721', '180722', '180723', '180724', '180725',\\\n",
    "           '180726', '180727', '180728', '180729', '180730', '180731', '180801', '180802', '180803', '180804',\\\n",
    "           '180805', '180806', '180807', '180808', '180809', '180810', '180811', '180812', '180813', '180814',\\\n",
    "           '180815', '180816', '180817', '180818', '180819', '180820', '180821', '180822', \\\n",
    "            '180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "           '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "           '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "            '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "           '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015', \\\n",
    "           '181016', '181017', '181018', '181019', '181020', '181021',\\\n",
    "            '181022', '181023', '181024', '181025', '181026', '181027', '181028', '181029', '181030', \\\n",
    "           '181031', '181101', '181102', '181103', '181104', '181105', '181106', '181107', '181108', '181109',\\\n",
    "           '181110', '181111','181112','181113']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = ['180828', '180829', '180830', '180831', '180901', '180902', '180903', '180904', '180905',\\\n",
    "          '180906', '180907', '180908', '180909', '180910', '180911', '180912', '180913', '180914', '180915',\\\n",
    "          '180916', '180917', '180918', '180919', '180920', '180921', '180922', '180923', '180924', '180925', \\\n",
    "          '180926', '180927', '180928', '180929', '180930', '181001', '181002', '181003', '181004', '181005', \\\n",
    "          '181006', '181007', '181008', '181009', '181010', '181011', '181012', '181013', '181014', '181015']\n",
    "\n",
    "valid_list = ['181016', '181017', '181018', '181019', '181020', '181021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180828 180829 180830 180831 180901 180902 180903 180904 180905 180906 180907 180908 180909 180910 180911 180912 180913 180914 180915 180916 180917 180918 180919 180920 180921 180922 180923 180924 180925 180926 180927 180928 180929 180930 181001 181002 181003 181004 181005 181006 181007 181008 181009 181010 181011 181012 181013 181014 181015 181016 181017 181018 181019 181020 181021 181022 181023 181024 181025 181026 181027 181028 181029 181101 181030 181031 181101 181102 181103 181104 \n",
      "\n",
      "(674914, 105)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 划分训练集， 验证集 测试集\n",
    "str_cols = ['order_id','job_name',\\\n",
    "            'start_time','end_time',\\\n",
    "            'day_0_bef_end_time']\n",
    "features_all_merge = pd.read_csv('edt_no_upjob_score1120.csv')\n",
    "features_all_merge = features_all_merge['feature'][:100]\n",
    "#read_cols = list(set(str_cols+features_all))\n",
    "read_cols = list(set(str_cols+list(features_all_merge)))\n",
    "\n",
    "# read_cols = [cl for cl in read_cols if cl not in del_cols]\n",
    "\n",
    "train_df = []\n",
    "n_i = 1  #选取第几轮数据切片\n",
    "#\n",
    "for day in train_list:\n",
    "    day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\dt_no_upjob_train\\no_up_%s.csv'%day,nrows=20000,usecols=read_cols)\n",
    "    \n",
    "    day_all_data = day_all_data[day_all_data.job_name.notnull()]\n",
    "\n",
    "\n",
    "    #过滤结束日期超过2天的\n",
    "    #print(day_all_data.shape)\n",
    "    day_after_2 = day_all[day_all.index(day)+2]\n",
    "    day_after_2_int = int('20'+day_after_2+'235959')\n",
    "    day_all_data = day_all_data[day_all_data.end_time<day_after_2_int]\n",
    "\n",
    "    train_df.append(day_all_data)\n",
    "    print(day,end=' ')\n",
    "    \n",
    "train = pd.concat(train_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# valid_df = []\n",
    "# for day in valid_list:\n",
    "#     print(day,end=' ')\n",
    "#     if day >='181105':\n",
    "#         day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\dt_no_upjob_train\\no_up_%s.csv'%day,nrows=40000,usecols=read_cols)\n",
    "#     else:\n",
    "#         day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\dt_no_upjob_train\\no_up_%s.csv'%day,nrows=10000,usecols=read_cols)\n",
    "#     day_all_data = day_all_data[day_all_data.job_name.notnull()]\n",
    "#     day_after_2 = day_all[day_all.index(day)+1]\n",
    "#     day_after_2_int = int('20'+day_after_2+'235959')\n",
    "#     day_all_data = day_all_data[day_all_data.end_time<day_after_2_int]\n",
    "    \n",
    "#     print(day_all_data.shape)\n",
    "#     valid_df.append(day_all_data)\n",
    "    \n",
    "# valid = pd.concat(valid_df, ignore_index=True)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(train.shape)\n",
    "# print(valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(607422, 100)\n",
      "(67492, 100)\n"
     ]
    }
   ],
   "source": [
    "cols_train =[clm for clm in train.columns if clm not in ['order_id','job_name','v_date','order_d','from_time_1000_start',\\\n",
    "                                                            'start_time','end_time','order_id','job_name','day_0_bef_start_time',\\\n",
    "                                                            'day_0_bef_end_time','day_bef_0_dt','no_up_job_name']]\n",
    "\n",
    "\n",
    "# valid_x = valid[cols_train]\n",
    "# valid_y = valid['day_0_bef_end_time']\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(train[cols_train],train['day_0_bef_end_time'],random_state=33,test_size=0.1)\n",
    "\n",
    "# train_y = train_y.fillna(train_y.mean())\n",
    "# valid_y = valid_y.fillna(valid_y.mean())\n",
    "# test_y = test_y.fillna(test_y.mean())  \n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Start predicting...\n",
      "The MAE of prediction train_data is: 158.797510079\n",
      "The MSE of prediction train_data is: 75416.2954146\n"
     ]
    }
   ],
   "source": [
    "# lightgbm 算法预测\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "\n",
    "features = features_all_merge[:95]\n",
    "\n",
    "y_train = train_y.values\n",
    "y_test = test_y.values\n",
    "\n",
    "# X_train = train_x.values\n",
    "# X_test = test_x.values\n",
    "X_train = train_x[features].values\n",
    "X_test = test_x[features].values\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train,silent=True)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {'task': 'train',\n",
    "   'boosting_type': 'gbdt',\n",
    "   'objective': 'regression',\n",
    "   'metric':  'l2',\n",
    "   'num_leaves': 2**2,\n",
    "   'learning_rate': 0.1,\n",
    "   'feature_fraction': 0.9,\n",
    "   'bagging_fraction': 0.9,\n",
    "   'bagging_freq': 5,\n",
    "   'verbose': 50,\n",
    "    'verbose_eval':50}\n",
    "  \n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=25,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=10,\n",
    "                verbose_eval=False)\n",
    "\n",
    "# print('Save model...')\n",
    "\n",
    "# # save model to file\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(gbm,'edt_gbm.pkl')\n",
    "# clf = joblib.load(\"edt_gbm.pkl\")\n",
    "\n",
    "# gbm.save_model('lightgbm_model_edt.txt')\n",
    "print('Start predicting...')\n",
    "\n",
    "\n",
    "# predict\n",
    "\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "#vlid_pred = gbm.predict(valid_x[features], num_iteration=gbm.best_iteration)\n",
    "#clf_pred = gbm.predict(valid_x, num_iteration=gbm.best_iteration)\n",
    "# eval print(y_pred)\n",
    "print('The MAE of prediction train_data is:', mean_absolute_error(y_test, y_pred))\n",
    "#print('The MAE of prediction valid_data is:', mean_absolute_error(valid_y, vlid_pred))\n",
    "# print('The mean_absolute_error of prediction valid_data is:', mean_absolute_error(valid_y, clf_pred))\n",
    "print('The MSE of prediction train_data is:', mean_squared_error(y_test, y_pred))\n",
    "#print('The MSE of prediction valid_data is:', mean_squared_error(valid_y, vlid_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2\n",
    "The MAE of prediction train_data is: 147.528779835\n",
    "The MAE of prediction valid_data is: 145.179691176\n",
    "The MSE of prediction train_data is: 60539.5363992\n",
    "The MSE of prediction valid_data is: 52791.5567012\n",
    "huber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181016 (29745, 105)\n",
      "The MAE of valid_data is: 98.8298820837\n",
      "The MSE of valid_data is: 25596.9703741\n",
      "181017 (30334, 105)\n",
      "The MAE of valid_data is: 162.925836088\n",
      "The MSE of valid_data is: 59134.4125538\n",
      "181018 (29400, 105)\n",
      "The MAE of valid_data is: 85.2655094982\n",
      "The MSE of valid_data is: 12584.4780502\n",
      "181019 (29086, 105)\n",
      "The MAE of valid_data is: 88.0245336477\n",
      "The MSE of valid_data is: 14296.2255746\n",
      "181020 (29178, 105)\n",
      "The MAE of valid_data is: 86.0647249574\n",
      "The MSE of valid_data is: 13178.3595329\n",
      "181021 (30204, 105)\n",
      "The MAE of valid_data is: 113.552238136\n",
      "The MSE of valid_data is: 33454.0231408\n"
     ]
    }
   ],
   "source": [
    "#预测集：pred_list\n",
    "\n",
    "for day in valid_list:\n",
    "    print(day,end=' ')\n",
    "    #,usecols=read_cols\n",
    "    day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\dt_no_upjob_train\\no_up_%s.csv'%day,usecols=read_cols)\n",
    "    day_all_data = day_all_data[day_all_data.job_name.notnull()]\n",
    "    day_after_2 = day_all[day_all.index(day)+1]\n",
    "    day_after_2_int = int('20'+day_after_2+'045959')\n",
    "    day_all_data = day_all_data[day_all_data.end_time<day_after_2_int]\n",
    "    \n",
    "    print(day_all_data.shape)\n",
    "    day_all_data.index = range(len(day_all_data))\n",
    "    \n",
    "#     day_all_data['his_evet_count_null'] = day_all_data['all_count'].apply(lambda x:x is None).apply(int)\n",
    "#     day_all_data.fillna(0,inplace=True)\n",
    "\n",
    "    #valid_x_i = day_all_data[features]\n",
    "    valid_x_i = day_all_data[features]\n",
    "    valid_y_i = day_all_data['day_0_bef_end_time']\n",
    "    \n",
    "    vlid_pred_i = gbm.predict(valid_x_i[features], num_iteration=gbm.best_iteration)\n",
    "    \n",
    "    day_all_data = day_all_data[['job_name','day_0_bef_end_time']]\n",
    "    day_all_data['pred_edt'] = vlid_pred_i\n",
    "    day_all_data['pred_edt_error'] = day_all_data[['pred_edt','day_0_bef_end_time']].apply(lambda x:abs(x[0]-x[1]),axis=1)\n",
    "    \n",
    "    pre_pred_dt = pd.read_csv('.\\pred_dt\\pre_dt_%s.csv'%day)\n",
    "    pre_pred_dt = pre_pred_dt[['job_name','end_time','day_bef_0_dt','pre_dt','error']]\n",
    "    \n",
    "    day_all_data = day_all_data.merge(pre_pred_dt,on='job_name',how='left')\n",
    "    print('The MAE of valid_data is:', mean_absolute_error(valid_y_i, vlid_pred_i))\n",
    "    print('The MSE of valid_data is:', mean_squared_error(valid_y_i, vlid_pred_i))\n",
    "    \n",
    "    day_all_data.to_csv('./pred_dt/noup_job_edt_%s.csv'%day,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181105 (31608, 105) (22455, 3)\n",
      "The MAE is: 115.967624782\n",
      "The MSE is: 37612.9664037\n",
      "181106 (30868, 105) (21744, 3)\n",
      "The MAE is: 122.871382769\n",
      "The MSE is: 45548.3648892\n",
      "181107 (31289, 105) (17793, 3)\n",
      "The MAE is: 135.721607187\n",
      "The MSE is: 58530.0881115\n",
      "181108 (31209, 105) (15537, 3)\n",
      "The MAE is: 155.455836793\n",
      "The MSE is: 61625.2994215\n",
      "181109 (30749, 105) (12260, 3)\n",
      "The MAE is: 188.891827171\n",
      "The MSE is: 80872.9901137\n",
      "181110 (31289, 105) (9158, 3)\n",
      "The MAE is: 237.265823143\n",
      "The MSE is: 114155.305128\n",
      "181111 (29630, 105) (133, 3)\n",
      "The MAE is: 290.271521791\n",
      "The MSE is: 155110.810246\n"
     ]
    }
   ],
   "source": [
    "#预测集：pred_list\n",
    "\n",
    "for day in valid_list:\n",
    "    print(day,end=' ')\n",
    "    #,usecols=read_cols\n",
    "    day_all_data = pd.read_csv(r'E:\\jupyter\\CTM\\data_train\\dt_no_upjob_train\\no_up_%s.csv'%day,usecols=read_cols)\n",
    "    day_all_data = day_all_data[day_all_data.job_name.notnull()]\n",
    "#     day_after_2 = day_all[day_all.index(day)+1]\n",
    "#     day_after_2_int = int('20'+day_after_2+'045959')\n",
    "#     day_all_data = day_all_data[day_all_data.end_time<day_after_2_int]\n",
    "    \n",
    "    print(day_all_data.shape,end=' ')\n",
    "    day_all_data.index = range(len(day_all_data))\n",
    "    \n",
    "#     day_all_data['his_evet_count_null'] = day_all_data['all_count'].apply(lambda x:x is None).apply(int)\n",
    "#     day_all_data.fillna(0,inplace=True)\n",
    "\n",
    "    #valid_x_i = day_all_data[features]\n",
    "    valid_x_i = day_all_data[features]\n",
    "#     valid_y_i = day_all_data['day_0_bef_end_time']\n",
    "    \n",
    "    vlid_pred_i = gbm.predict(valid_x_i[features], num_iteration=gbm.best_iteration)\n",
    "    \n",
    "    day_all_data = day_all_data[['job_name','day_0_bef_end_time']]\n",
    "    day_all_data['pred_edt'] = vlid_pred_i\n",
    "    #day_all_data['pred_edt_error'] = day_all_data[['pred_edt','day_0_bef_end_time']].apply(lambda x:abs(x[0]-x[1]),axis=1)\n",
    "    \n",
    "#     pre_pred_dt = pd.read_csv('.\\pred_dt\\pre_dt_%s.csv'%day)\n",
    "#     pre_pred_dt = pre_pred_dt[['job_name','end_time','day_bef_0_dt','pre_dt','error']]\n",
    "    \n",
    "#     day_all_data = day_all_data.merge(pre_pred_dt,on='job_name',how='left')\n",
    "\n",
    "    print_data =  day_all_data[day_all_data.day_0_bef_end_time!=-1]\n",
    "    #print_data =  day_all_data[day_all_data.day_0_bef_end_time<1440]\n",
    "    \n",
    "    print(print_data.shape)\n",
    "    print('The MAE is:', mean_absolute_error(print_data['day_0_bef_end_time'], print_data['pred_edt']))\n",
    "    print('The MSE is:', mean_squared_error(print_data['day_0_bef_end_time'], print_data['pred_edt']))\n",
    "    \n",
    "    day_all_data.to_csv('./pred_dt/noup_job_edt_%s.csv'%day,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "181105 (31608, 105) (22455, 3)\n",
    "The MAE of valid_data is: 112.549258822\n",
    "The MSE of valid_data is: 36996.8896877\n",
    "181106 (30868, 105) (21744, 3)\n",
    "The MAE of valid_data is: 119.052671642\n",
    "The MSE of valid_data is: 44523.8389065\n",
    "181107 (31289, 105) (17793, 3)\n",
    "The MAE of valid_data is: 132.498470949\n",
    "The MSE of valid_data is: 57534.428573\n",
    "181108 (31209, 105) (15537, 3)\n",
    "The MAE of valid_data is: 153.147750604\n",
    "The MSE of valid_data is: 62160.8221298\n",
    "181109 (30749, 105) (12260, 3)\n",
    "The MAE of valid_data is: 185.435814387\n",
    "The MSE of valid_data is: 80523.6256096\n",
    "181110 (31289, 105) (9158, 3)\n",
    "The MAE of valid_data is: 232.692373669\n",
    "The MSE of valid_data is: 111077.227455\n",
    "181111 (29630, 105) (133, 3)\n",
    "The MAE of valid_data is: 287.10094649\n",
    "The MSE of valid_data is: 127045.225806"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
